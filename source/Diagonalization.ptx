<section xml:id="Diagonalization">
  <title>Diagonalization</title>
  <exercise>  
    <statement>
      <p>
        Compute the following matrix products.
        <ol>
          <li>
            <p>
              <m>\left[ \begin{array}{rrr} 1 \amp 2 \amp 3 \\ 4 \amp 5 \amp 6 \\ 7 \amp 8 \amp 9 \end{array} \right]\left[ \begin{array}{ccc} 10 \amp 0 \amp 0 \\ 0 \amp 100 \amp 0 \\ 0 \amp 0 \amp 1000 \end{array} \right]=</m>
            </p>
          </li>
          <li>
            <p>
              <m>\left[ \begin{array}{ccc} 10 \amp 0 \amp 0 \\ 0 \amp 100 \amp 0 \\ 0 \amp 0 \amp 1000 \end{array} \right]\left[ \begin{array}{rrr} 1 \amp 2 \amp 3 \\ 4 \amp 5 \amp 6 \\ 7 \amp 8 \amp 9 \end{array} \right]=</m>
            </p>
          </li>
        </ol>
      </p>
    </statement>
  </exercise>
  <exercise>
    <statement>
      <p>
        Use that <m> \vect{v_1} =(3,0,1)</m>, <m> \vect{v_2} =(0,2,1)</m> and <m> \vect{v_3} =(1,1,1)</m> are the eigenvectors corresponding to eigenvalues <m>\lambda_1 =0</m>,
        <m>\lambda_2=2</m> and <m>\lambda_3=1</m> for the matrix
        <m>\mtx{A} = \left[ \begin{array}{rrr} -2 \amp -3 \amp 6 \\ 2 \amp 5 \amp -6 \\ 0 \amp 1 \amp 0 \end{array} \right]</m> to fill in the blanks below.
      </p>
      <p>
        <m>\left[ \begin{array}{rrr} -2 \amp -3 \amp 6 \\ 2 \amp 5 \amp -6 \\ 0 \amp 1 \amp 0 \end{array} \right]\left[ \begin{array}{ccc} \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \\ \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \\ \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \end{array} \right] = \left[ \begin{array}{ccc} \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \\ \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \\ \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \end{array} \right]\left[ \begin{array}{ccc} \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \\ \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \\ \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \end{array} \right]</m>
      </p>
      <p>
        and
      </p>
      <p>
        <m>\left[ \begin{array}{rrr} -2 \amp -3 \amp 6 \\ 2 \amp 5 \amp -6 \\ 0 \amp 1 \amp 0 \end{array} \right] = \left[ \begin{array}{ccc} \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \\ \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \\ \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \end{array} \right] \left[ \begin{array}{ccc} \underline{\hspace{.2in} } \amp 0 \amp 0 \\ 0 \amp \underline{\hspace{.2in} } \amp 0 \\ 0 \amp 0 \amp \underline{\hspace{.2in} } \end{array} \right]\left[ \begin{array}{ccc} \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \\ \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \\ \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \amp \underline{\hspace{.2in} } \end{array} \right]</m>
      </p>
    </statement>
  </exercise>
  <exercise>
    <statement>
      <p>
        Given <m>\mtx{A} = \left[ \begin{array}{rr} 1 \amp -1 \\ 2 \amp 4 \end{array} \right]</m>,
        find invertible matrix <m>\mtx{P}</m> and diagonal matrix <m>\mtx{D}</m> such that <m>\mtx{A} = \mtx{P}\mtx{D}\mtx{P}^{-1}</m>
      </p>
    </statement>
  </exercise>
  <theorem>
    <statement>
      <p>
        If an <m>n\times n</m> matrix has n linearly independent eigenvectors then there exists an invertible matrix <m>\mtx{P}</m> and a diagonal matrix <m>\mtx{D}</m> such that:
        <me>
          \mtx{A} = \mtx{P }\mtx{D}\ \mtx{P}^{\ -1}
        </me>
      </p>
    </statement>
  </theorem>
  <proposition>
   <p>
      If an <m>n\times n</m> matrix <m>\mtx{A}</m> has n linearly independent eigenvectors then det(<m>\mtx{A}</m>) is the product of the n corresponding eigenvalues.
   </p>
  </proposition>
  <question>
   <p>
    How would Theorem 35 help us efficiently compute <m>\mtx{A}^{100}</m>?
   </p>
  </question>
</section>